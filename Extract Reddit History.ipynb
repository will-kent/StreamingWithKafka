{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2abfd44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "import configparser\n",
    "import praw\n",
    "from pushshift_py import PushshiftAPI\n",
    "import datetime as dt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8162d8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['src/configuration/config.cfg']"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read passwords and secrets from config file\n",
    "config_parser = configparser.ConfigParser()\n",
    "config_parser.read(\"src/configuration/config.cfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "7d020402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "reddit_client_id = config_parser[\"praw\"][\"client_id\"]\n",
    "reddit_client_secret = config_parser[\"praw\"][\"client_secret\"]\n",
    "reddit_password = config_parser[\"praw\"][\"password\"]\n",
    "reddit_username = config_parser[\"praw\"][\"username\"]\n",
    "reddit_agent = config_parser[\"praw\"][\"user_agent\"] + reddit_username\n",
    "sub_reddit = config_parser[\"praw\"][\"subreddit\"]\n",
    "sub_file_prefix = \"submissions\"\n",
    "comment_file_prefix = \"comment\"\n",
    "years = [2021]\n",
    "months = range(2,6)\n",
    "sub_columns = [\"id\",'author_fullname','title','score','author_premium','domain','over_18','subreddit_id','permalink','parent_whitelist_status','url','created_utc']\n",
    "comm_columns = [\"id\",'link_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "163a76aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish connection to reddit\n",
    "reddit = praw.Reddit(\n",
    "    client_id=reddit_client_id,\n",
    "    client_secret=reddit_client_secret,\n",
    "    password=reddit_password,\n",
    "    user_agent=reddit_agent,\n",
    "    username=reddit_username,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "645d065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subreddit_submission_history(sub, year, month):\n",
    "    api = PushshiftAPI()\n",
    "    last_day = calendar.monthrange(year, month)[1] # last day of month\n",
    "    after = start_epoch=int(dt.datetime(year, month, 1).timestamp())\n",
    "    before = start_epoch=int(dt.datetime(year, month, last_day).timestamp())\n",
    "\n",
    "    submissions = api.search_submissions(subreddit=sub,\n",
    "                             before=before,\n",
    "                             after=after)\n",
    "    results = []\n",
    "    for submission in submissions:\n",
    "        results.append(submission)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "57b58896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subreddit_comment_history(sub, year, month):\n",
    "    api = PushshiftAPI()\n",
    "    last_day = calendar.monthrange(year, month)[1] # last day of month\n",
    "    after = start_epoch=int(dt.datetime(year, month, 1).timestamp())\n",
    "    before = start_epoch=int(dt.datetime(year, month, last_day).timestamp())\n",
    "    \n",
    "    comments = api.search_comments(subreddit=sub,\n",
    "                             before=before,\n",
    "                             after=after)\n",
    "    \n",
    "    results = []\n",
    "    for comment in comments:\n",
    "        results.append(comment)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eed950",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    for month in months:\n",
    "        # Extract submissions for year and month\n",
    "        yearmonth = year * 100 + month\n",
    "        sub_output = get_subreddit_submission_history(sub=sub_reddit, year=year, month=month)\n",
    "        print(\"For \" + str(yearmonth) + \" \" + str(len(sub_output)) + \" submissions were extracted\")\n",
    "        s_df = pd.DataFrame([c.d_ for c in sub_output])\n",
    "        s_df = s_df[sub_columns]\n",
    "        sub_filename = sub_file_prefix + \"_\" + str(yearmonth) + \".csv\"\n",
    "        s_df.to_csv(sub_filename)\n",
    "        \n",
    "        # Extract comments for year and month\n",
    "        comm_output = get_subreddit_comment_history(sub=sub_reddit, year=year, month=month)\n",
    "        print(\"For \" + str(yearmonth) + \" \" + str(len(comm_output)) + \" comments were extracted\")\n",
    "        c_df = pd.DataFrame([c.d_ for c in comm_output])\n",
    "        c_df = c_df[comm_columns]\n",
    "        comm_filename = comment_file_prefix + \"_\" + str(yearmonth) + \".csv\"\n",
    "        c_df.to_csv(comm_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "29c41627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['subreddit_name_prefixed'] = submission.subreddit_name_prefixed\n",
    "#data['name'] = submission.name\n",
    "##data['upvote_ratio'] = submission.upvote_ratio\n",
    "#data['ups'] = submission.ups\n",
    "#data['created'] = submission.created\n",
    "#data['url_overridden_by_dest'] = submission.url_overridden_by_dest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "52f387ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 6, 10, 13, 31, 10, 510164)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9132f025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3_ei4wgq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3_ei9quo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3_ei1wf9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3_ei5h2w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t3_ei5h2w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4305</th>\n",
       "      <td>t3_ei4wgq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4306</th>\n",
       "      <td>t3_ei9quo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>t3_ei1wf9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4308</th>\n",
       "      <td>t3_ei4wgq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>t3_ei9quo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4310 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        link_id\n",
       "0     t3_ei4wgq\n",
       "1     t3_ei9quo\n",
       "2     t3_ei1wf9\n",
       "3     t3_ei5h2w\n",
       "4     t3_ei5h2w\n",
       "...         ...\n",
       "4305  t3_ei4wgq\n",
       "4306  t3_ei9quo\n",
       "4307  t3_ei1wf9\n",
       "4308  t3_ei4wgq\n",
       "4309  t3_ei9quo\n",
       "\n",
       "[4310 rows x 1 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_df[['link_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5670d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import urllib\n",
    "import time\n",
    "import json\n",
    "\n",
    "def get_data(object_type, username='', subreddit='', search_query='', max_time=None, min_time=1609459200):\n",
    "    # start from current time if not specified\n",
    "    if max_time is None:\n",
    "        max_time = int(time.time())\n",
    "\n",
    "    # generate filter string\n",
    "    filter_string = urllib.parse.urlencode(\n",
    "        {k: v for k, v in zip(\n",
    "            ['author', 'subreddit', 'q'],\n",
    "            [username, subreddit, search_query]) if v != \"\"})\n",
    "\n",
    "    url_format = \"https://api.pushshift.io/reddit/search/{}/?size=500&sort=desc&{}&before={}\"\n",
    "\n",
    "    before = max_time\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    while before > min_time:\n",
    "        url = url_format.format(object_type, filter_string, before)\n",
    "        resp = requests.get(url)\n",
    "\n",
    "        # convert records to dataframe\n",
    "        dfi = pd.json_normalize(json.loads(resp.text)['data'])\n",
    "        \n",
    "        if object_type == 'comment':\n",
    "            #dfi = dfi.rename(columns={'created_utc': 'date', 'body': 'comment'})\n",
    "            df = pd.concat([df, dfi[comm_columns]])\n",
    "        elif object_type == 'submission':\n",
    "            #dfi = dfi.rename(columns={'created_utc': 'date', 'selftext': 'post'})\n",
    "            #dfi = dfi[dfi['post'].ne('')]\n",
    "            df = pd.concat([df, dfi[sub_columns]])\n",
    "\n",
    "        # set `before` to the earliest comment/post in the results\n",
    "        # next time we call requests.get(...) we will only get comments/posts before\n",
    "        # the earliest that we already have, thus not fetching any duplicates\n",
    "        before = dfi['created_utc'].min()\n",
    "\n",
    "        # if needed\n",
    "        # time.sleep(1)\n",
    "        \n",
    "    return df\n",
    "#Testing by getting the comments and checking for duplicate values (by id):\n",
    "\n",
    "username = \"\"\n",
    "subreddit = \"worldnews\"\n",
    "\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        last_day = calendar.monthrange(year, month)[1] # last day of month\n",
    "        after = start_epoch=int(dt.datetime(year, month, 1).timestamp())\n",
    "        before = start_epoch=int(dt.datetime(year, month, last_day).timestamp())\n",
    "    \n",
    "        df_comments = get_data(\n",
    "            object_type='submission',\n",
    "            username=username,\n",
    "            subreddit=subreddit,\n",
    "            max_time=before,\n",
    "            min_time=after)\n",
    "\n",
    "        df_comments['id'].duplicated().any()    # False\n",
    "        total = df_comments['id'].nunique()             # 2200\n",
    "        yearmonth = year * 100 + month\n",
    "        print(\"For \" + str(yearmonth) + \" \" + str(total) + \" values were extracted\")\n",
    "        \n",
    "        sub_filename = sub_file_prefix + \"_\" + str(yearmonth) + \".csv\"\n",
    "\n",
    "        df_comments.to_csv(sub_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "469bdd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34200\n"
     ]
    }
   ],
   "source": [
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5253a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_filename = sub_file_prefix + \"_\" + str(yearmonth) + \".csv\"\n",
    "\n",
    "df_comments.to_csv(sub_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76f1b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
